{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ecf4393-9629-440b-9d49-49fa673c1de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading catalog...\n",
      "\n",
      "Processing city: Cairo\n",
      "  Processing model: MPI-ESM1-2-LR\n",
      "  Processing model: MIROC6\n",
      "  Processing model: EC-Earth3\n",
      "  Saved: CMIP6_extracts/Cairo_data.csv\n",
      "\n",
      "Processing city: Helsinki\n",
      "  Processing model: MPI-ESM1-2-LR\n",
      "  Processing model: MIROC6\n",
      "  Processing model: EC-Earth3\n",
      "  Saved: CMIP6_extracts/Helsinki_data.csv\n",
      "\n",
      "Processing city: New_Delhi\n",
      "  Processing model: MPI-ESM1-2-LR\n",
      "  Processing model: MIROC6\n",
      "  Processing model: EC-Earth3\n",
      "  Saved: CMIP6_extracts/New_Delhi_data.csv\n",
      "\n",
      "All done in 1653.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CMIP6 Climate Data Extraction \n",
    "---------------------------------\n",
    "Author: Aurela Sakaj\n",
    "Date: 2025-04-09\n",
    "\n",
    "This script extracts and processes climate model data from the CMIP6 archive for specified cities.\n",
    "It handles temperature (converted to °C) and precipitation (converted to mm/day) data,\n",
    "combines results from multiple models and scenarios, and saves them as CSV files.\n",
    "\"\"\"\n",
    "\n",
    "import intake\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "\n",
    "# Dictionary of target cities with their (latitude, longitude) coordinates\n",
    "LOCATIONS = {\n",
    "    \"Cairo\": (30.0444, 31.2357),\n",
    "    \"Helsinki\": (60.1695, 24.9354),\n",
    "    \"New_Delhi\": (28.6139, 77.2090)  \n",
    "\n",
    "}\n",
    "\n",
    "MODELS = [\"MPI-ESM1-2-LR\", \"MIROC6\", \"EC-Earth3\"]\n",
    "SCENARIOS = ['historical', 'ssp245', 'ssp585']\n",
    "VARIABLES = ['tas', 'pr']\n",
    "SAVE_DIR = \"CMIP6_extracts\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Utility Functions\n",
    "\n",
    "def extract_and_convert(ds, lat, lon):\n",
    "    tas = ds['tas'].sel(lat=lat, lon=lon, method='nearest') - 273.15  # K to °C\n",
    "    pr = ds['pr'].sel(lat=lat, lon=lon, method='nearest') * 86400    # kg/m²/s to mm/day\n",
    "    df = xr.Dataset({'temperature_C': tas, 'precipitation_mm_per_day': pr}).to_dataframe().reset_index()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    return df[['time', 'temperature_C', 'precipitation_mm_per_day']]\n",
    "\n",
    "# Load catalog\n",
    "print(\"Loading catalog...\")\n",
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Main Processing Loop \n",
    "\n",
    "for city, coords in LOCATIONS.items():\n",
    "    print(f\"\\nProcessing city: {city}\")\n",
    "    city_data = []\n",
    "\n",
    "    for model in MODELS:\n",
    "        print(f\"  Processing model: {model}\")\n",
    "\n",
    "        # Single search per model for all scenarios and variables\n",
    "        cat = col.search(\n",
    "            source_id=model,\n",
    "            experiment_id=SCENARIOS,\n",
    "            variable_id=VARIABLES,\n",
    "            table_id='Amon',\n",
    "            member_id='r1i1p1f1'\n",
    "        )\n",
    "\n",
    "        if cat.df.empty:\n",
    "            print(f\"    No data found for {model}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dsets = cat.to_dataset_dict(\n",
    "                zarr_kwargs={'consolidated': True, 'use_cftime': False},\n",
    "                storage_options={'token': 'anon'},\n",
    "                progressbar=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"    Error loading data: {e}\")\n",
    "            continue\n",
    "\n",
    "        model_frames = []\n",
    "\n",
    "        for key, ds in dsets.items():\n",
    "            scenario = ds.attrs.get(\"experiment_id\", \"\").lower()\n",
    "            if scenario not in SCENARIOS:\n",
    "                continue\n",
    "            if not all(var in ds for var in VARIABLES):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df = extract_and_convert(ds, *coords)\n",
    "                df['scenario'] = scenario\n",
    "                df['model'] = model\n",
    "                model_frames.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"    Failed extraction {key}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if model_frames:\n",
    "            city_data.append(pd.concat(model_frames))\n",
    "\n",
    "    # Combine and save city's data\n",
    "    if city_data:\n",
    "        combined_city_df = pd.concat(city_data).sort_values(by=['model', 'scenario', 'time'])\n",
    "        combined_city_df.to_csv(f\"{SAVE_DIR}/{city}_data.csv\", index=False)\n",
    "        print(f\"  Saved: {SAVE_DIR}/{city}_data.csv\")\n",
    "    else:\n",
    "        print(f\"  No data extracted for {city}.\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nAll done in {elapsed:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcf298-62c3-4496-ab94-8a040cbb1976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
